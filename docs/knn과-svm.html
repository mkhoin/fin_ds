<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 KNN과 SVM | 금융 데이터 사이언스</title>
  <meta name="description" content="Chapter 5 KNN과 SVM | 금융 데이터 사이언스" />
  <meta name="generator" content="bookdown 0.15 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 KNN과 SVM | 금융 데이터 사이언스" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 KNN과 SVM | 금융 데이터 사이언스" />
  
  
  

<meta name="author" content="이현열" />


<meta name="date" content="2019-11-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ridge-lasso.html"/>
<link rel="next" href="cart.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">금융 데이터 사이언스</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#사용-패키지"><i class="fa fa-check"></i>사용 패키지</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="머신러닝이란.html"><a href="머신러닝이란.html"><i class="fa fa-check"></i><b>1</b> 머신러닝이란?</a><ul>
<li class="chapter" data-level="1.1" data-path="머신러닝이란.html"><a href="머신러닝이란.html#지도학습supervised-learning"><i class="fa fa-check"></i><b>1.1</b> 지도학습(Supervised Learning)</a></li>
<li class="chapter" data-level="1.2" data-path="머신러닝이란.html"><a href="머신러닝이란.html#비지도학습unsupervised-learning"><i class="fa fa-check"></i><b>1.2</b> 비지도학습(Unsupervised Learning)</a></li>
<li class="chapter" data-level="1.3" data-path="머신러닝이란.html"><a href="머신러닝이란.html#딥러닝-강화학습reinforcement-learning"><i class="fa fa-check"></i><b>1.3</b> 딥러닝 / 강화학습(Reinforcement Learning)</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="회귀분석.html"><a href="회귀분석.html"><i class="fa fa-check"></i><b>2</b> 회귀분석</a><ul>
<li class="chapter" data-level="2.1" data-path="회귀분석.html"><a href="회귀분석.html#상관관계-이해하기"><i class="fa fa-check"></i><b>2.1</b> 상관관계 이해하기</a></li>
<li class="chapter" data-level="2.2" data-path="회귀분석.html"><a href="회귀분석.html#회귀의-이해"><i class="fa fa-check"></i><b>2.2</b> 회귀의 이해</a><ul>
<li class="chapter" data-level="2.2.1" data-path="회귀분석.html"><a href="회귀분석.html#보통-최소-제곱ols-추정"><i class="fa fa-check"></i><b>2.2.1</b> 보통 최소 제곱(OLS) 추정</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="회귀분석.html"><a href="회귀분석.html#단변량-회귀분석"><i class="fa fa-check"></i><b>2.3</b> 단변량 회귀분석</a><ul>
<li class="chapter" data-level="2.3.1" data-path="회귀분석.html"><a href="회귀분석.html#챌린저-호-데이터"><i class="fa fa-check"></i><b>2.3.1</b> 챌린저 호 데이터</a></li>
<li class="chapter" data-level="2.3.2" data-path="회귀분석.html"><a href="회귀분석.html#미국-와이오밍-주-용출량-예측"><i class="fa fa-check"></i><b>2.3.2</b> 미국 와이오밍 주 용출량 예측</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="회귀분석.html"><a href="회귀분석.html#다변량-회귀분석"><i class="fa fa-check"></i><b>2.4</b> 다변량 회귀분석</a><ul>
<li class="chapter" data-level="2.4.1" data-path="회귀분석.html"><a href="회귀분석.html#다이아몬드-데이터"><i class="fa fa-check"></i><b>2.4.1</b> 다이아몬드 데이터</a></li>
<li class="chapter" data-level="2.4.2" data-path="회귀분석.html"><a href="회귀분석.html#캘리포니아-물-가용량"><i class="fa fa-check"></i><b>2.4.2</b> 캘리포니아 물 가용량</a></li>
<li class="chapter" data-level="2.4.3" data-path="회귀분석.html"><a href="회귀분석.html#최적화를-통한-변수-선택"><i class="fa fa-check"></i><b>2.4.3</b> 최적화를 통한 변수 선택</a></li>
<li class="chapter" data-level="2.4.4" data-path="회귀분석.html"><a href="회귀분석.html#robustness-check"><i class="fa fa-check"></i><b>2.4.4</b> Robustness Check</a></li>
<li class="chapter" data-level="2.4.5" data-path="회귀분석.html"><a href="회귀분석.html#실제와-예측간의-차이"><i class="fa fa-check"></i><b>2.4.5</b> 실제와 예측간의 차이</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="회귀분석.html"><a href="회귀분석.html#다른-고려사항"><i class="fa fa-check"></i><b>2.5</b> 다른 고려사항</a><ul>
<li class="chapter" data-level="2.5.1" data-path="회귀분석.html"><a href="회귀분석.html#질적-피처"><i class="fa fa-check"></i><b>2.5.1</b> 질적 피처</a></li>
<li class="chapter" data-level="2.5.2" data-path="회귀분석.html"><a href="회귀분석.html#상호작용-항"><i class="fa fa-check"></i><b>2.5.2</b> 상호작용 항</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html"><i class="fa fa-check"></i><b>3</b> 로지스틱 회귀</a><ul>
<li class="chapter" data-level="3.1" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#오즈비"><i class="fa fa-check"></i><b>3.1</b> 오즈비</a></li>
<li class="chapter" data-level="3.2" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#로지스틱-회귀-1"><i class="fa fa-check"></i><b>3.2</b> 로지스틱 회귀</a></li>
<li class="chapter" data-level="3.3" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#입학-데이터-분석"><i class="fa fa-check"></i><b>3.3</b> 입학 데이터 분석</a></li>
<li class="chapter" data-level="3.4" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#위스콘신-유방암-데이터"><i class="fa fa-check"></i><b>3.4</b> 위스콘신 유방암 데이터</a><ul>
<li class="chapter" data-level="3.4.1" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#데이터-불러오기-및-편집"><i class="fa fa-check"></i><b>3.4.1</b> 데이터 불러오기 및 편집</a></li>
<li class="chapter" data-level="3.4.2" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#데이터-나누기"><i class="fa fa-check"></i><b>3.4.2</b> 데이터 나누기</a></li>
<li class="chapter" data-level="3.4.3" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#모형화"><i class="fa fa-check"></i><b>3.4.3</b> 모형화</a></li>
<li class="chapter" data-level="3.4.4" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#테스트-셋에-적용"><i class="fa fa-check"></i><b>3.4.4</b> 테스트 셋에 적용</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#교차검증을-포함한-로지스틱-회귀"><i class="fa fa-check"></i><b>3.5</b> 교차검증을 포함한 로지스틱 회귀</a></li>
<li class="chapter" data-level="3.6" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#bic-기준-최적의-피처-선택"><i class="fa fa-check"></i><b>3.6</b> BIC 기준 최적의 피처 선택</a></li>
<li class="chapter" data-level="3.7" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#roc"><i class="fa fa-check"></i><b>3.7</b> ROC</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ridge-lasso.html"><a href="ridge-lasso.html"><i class="fa fa-check"></i><b>4</b> RIDGE &amp; LASSO</a><ul>
<li class="chapter" data-level="4.1" data-path="ridge-lasso.html"><a href="ridge-lasso.html#규제화"><i class="fa fa-check"></i><b>4.1</b> 규제화</a><ul>
<li class="chapter" data-level="4.1.1" data-path="ridge-lasso.html"><a href="ridge-lasso.html#규제화의-종류"><i class="fa fa-check"></i><b>4.1.1</b> 규제화의 종류</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ridge-lasso.html"><a href="ridge-lasso.html#전립선암-데이터-분석"><i class="fa fa-check"></i><b>4.2</b> 전립선암 데이터 분석</a><ul>
<li class="chapter" data-level="4.2.1" data-path="ridge-lasso.html"><a href="ridge-lasso.html#데이터-불러오기-및-편집-1"><i class="fa fa-check"></i><b>4.2.1</b> 데이터 불러오기 및 편집</a></li>
<li class="chapter" data-level="4.2.2" data-path="ridge-lasso.html"><a href="ridge-lasso.html#데이터-나누기-1"><i class="fa fa-check"></i><b>4.2.2</b> 데이터 나누기</a></li>
<li class="chapter" data-level="4.2.3" data-path="ridge-lasso.html"><a href="ridge-lasso.html#모형화-1"><i class="fa fa-check"></i><b>4.2.3</b> 모형화</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="knn과-svm.html"><a href="knn과-svm.html"><i class="fa fa-check"></i><b>5</b> KNN과 SVM</a><ul>
<li class="chapter" data-level="5.1" data-path="knn과-svm.html"><a href="knn과-svm.html#knn"><i class="fa fa-check"></i><b>5.1</b> KNN</a></li>
<li class="chapter" data-level="5.2" data-path="knn과-svm.html"><a href="knn과-svm.html#svm"><i class="fa fa-check"></i><b>5.2</b> SVM</a></li>
<li class="chapter" data-level="5.3" data-path="knn과-svm.html"><a href="knn과-svm.html#데이터-불러오기-및-편집-2"><i class="fa fa-check"></i><b>5.3</b> 데이터 불러오기 및 편집</a><ul>
<li class="chapter" data-level="5.3.1" data-path="knn과-svm.html"><a href="knn과-svm.html#knn-1"><i class="fa fa-check"></i><b>5.3.1</b> KNN</a></li>
<li class="chapter" data-level="5.3.2" data-path="knn과-svm.html"><a href="knn과-svm.html#svm-1"><i class="fa fa-check"></i><b>5.3.2</b> SVM</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="cart.html"><a href="cart.html"><i class="fa fa-check"></i><b>6</b> CART</a><ul>
<li class="chapter" data-level="6.1" data-path="cart.html"><a href="cart.html#의사결정나무"><i class="fa fa-check"></i><b>6.1</b> 의사결정나무</a><ul>
<li class="chapter" data-level="6.1.1" data-path="cart.html"><a href="cart.html#랜덤-포레스트"><i class="fa fa-check"></i><b>6.1.1</b> 랜덤 포레스트</a></li>
<li class="chapter" data-level="6.1.2" data-path="cart.html"><a href="cart.html#익스트림-그레디언트-부스트-기법-xgboost"><i class="fa fa-check"></i><b>6.1.2</b> 익스트림 그레디언트 부스트 기법 (XGboost)</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="cart.html"><a href="cart.html#회귀-트리"><i class="fa fa-check"></i><b>6.2</b> 회귀 트리</a><ul>
<li class="chapter" data-level="6.2.1" data-path="cart.html"><a href="cart.html#데이터-불러오기-및-편집-3"><i class="fa fa-check"></i><b>6.2.1</b> 데이터 불러오기 및 편집</a></li>
<li class="chapter" data-level="6.2.2" data-path="cart.html"><a href="cart.html#모형화-2"><i class="fa fa-check"></i><b>6.2.2</b> 모형화</a></li>
<li class="chapter" data-level="6.2.3" data-path="cart.html"><a href="cart.html#프루닝가지치기"><i class="fa fa-check"></i><b>6.2.3</b> 프루닝(가지치기)</a></li>
<li class="chapter" data-level="6.2.4" data-path="cart.html"><a href="cart.html#랜덤-포레스트-회귀-트리"><i class="fa fa-check"></i><b>6.2.4</b> 랜덤 포레스트: 회귀 트리</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="cart.html"><a href="cart.html#분류-트리"><i class="fa fa-check"></i><b>6.3</b> 분류 트리</a><ul>
<li class="chapter" data-level="6.3.1" data-path="cart.html"><a href="cart.html#데이터-불러오기-및-편집-4"><i class="fa fa-check"></i><b>6.3.1</b> 데이터 불러오기 및 편집</a></li>
<li class="chapter" data-level="6.3.2" data-path="cart.html"><a href="cart.html#랜덤-포레스트-분류-트리"><i class="fa fa-check"></i><b>6.3.2</b> 랜덤 포레스트: 분류 트리</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="cart.html"><a href="cart.html#익스트림-그레디언트-부스트-기법-xgboost-1"><i class="fa fa-check"></i><b>6.4</b> 익스트림 그레디언트 부스트 기법 (XGboost)</a><ul>
<li class="chapter" data-level="6.4.1" data-path="cart.html"><a href="cart.html#데이터-불러오기-및-편집-5"><i class="fa fa-check"></i><b>6.4.1</b> 데이터 불러오기 및 편집</a></li>
<li class="chapter" data-level="6.4.2" data-path="cart.html"><a href="cart.html#랜덤-포레스트-1"><i class="fa fa-check"></i><b>6.4.2</b> 랜덤 포레스트</a></li>
<li class="chapter" data-level="6.4.3" data-path="cart.html"><a href="cart.html#xgboost-모형-만들기"><i class="fa fa-check"></i><b>6.4.3</b> XGboost 모형 만들기</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>7</b> PCA</a><ul>
<li class="chapter" data-level="7.1" data-path="pca.html"><a href="pca.html#주성분분석pca"><i class="fa fa-check"></i><b>7.1</b> 주성분분석(PCA)</a></li>
<li class="chapter" data-level="7.2" data-path="pca.html"><a href="pca.html#iris-데이터-분석"><i class="fa fa-check"></i><b>7.2</b> iris 데이터 분석</a><ul>
<li class="chapter" data-level="7.2.1" data-path="pca.html"><a href="pca.html#데이터-불러오기"><i class="fa fa-check"></i><b>7.2.1</b> 데이터 불러오기</a></li>
<li class="chapter" data-level="7.2.2" data-path="pca.html"><a href="pca.html#모형화-3"><i class="fa fa-check"></i><b>7.2.2</b> 모형화</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="pca.html"><a href="pca.html#북미-프로-아이스하키-리그-데이터-분석"><i class="fa fa-check"></i><b>7.3</b> 북미 프로 아이스하키 리그 데이터 분석</a><ul>
<li class="chapter" data-level="7.3.1" data-path="pca.html"><a href="pca.html#데이터-불러오기-1"><i class="fa fa-check"></i><b>7.3.1</b> 데이터 불러오기</a></li>
<li class="chapter" data-level="7.3.2" data-path="pca.html"><a href="pca.html#성분-추출"><i class="fa fa-check"></i><b>7.3.2</b> 성분 추출</a></li>
<li class="chapter" data-level="7.3.3" data-path="pca.html"><a href="pca.html#직각-회전과-해석"><i class="fa fa-check"></i><b>7.3.3</b> 직각 회전과 해석</a></li>
<li class="chapter" data-level="7.3.4" data-path="pca.html"><a href="pca.html#요인-점수-생성"><i class="fa fa-check"></i><b>7.3.4</b> 요인 점수 생성</a></li>
<li class="chapter" data-level="7.3.5" data-path="pca.html"><a href="pca.html#회귀-분석"><i class="fa fa-check"></i><b>7.3.5</b> 회귀 분석</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="군집화-분석.html"><a href="군집화-분석.html"><i class="fa fa-check"></i><b>8</b> 군집화 분석</a><ul>
<li class="chapter" data-level="8.1" data-path="군집화-분석.html"><a href="군집화-분석.html#k-means-iris-데이터"><i class="fa fa-check"></i><b>8.1</b> K-Means (iris 데이터)</a><ul>
<li class="chapter" data-level="8.1.1" data-path="군집화-분석.html"><a href="군집화-분석.html#데이터-불러오기-및-편집-6"><i class="fa fa-check"></i><b>8.1.1</b> 데이터 불러오기 및 편집</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="군집화-분석.html"><a href="군집화-분석.html#와인-데이터-분석"><i class="fa fa-check"></i><b>8.2</b> 와인 데이터 분석</a><ul>
<li class="chapter" data-level="8.2.1" data-path="군집화-분석.html"><a href="군집화-분석.html#데이터-불러오기-및-편집-7"><i class="fa fa-check"></i><b>8.2.1</b> 데이터 불러오기 및 편집</a></li>
<li class="chapter" data-level="8.2.2" data-path="군집화-분석.html"><a href="군집화-분석.html#k-평균-군집화"><i class="fa fa-check"></i><b>8.2.2</b> K-평균 군집화</a></li>
<li class="chapter" data-level="8.2.3" data-path="군집화-분석.html"><a href="군집화-분석.html#계층적-군집화"><i class="fa fa-check"></i><b>8.2.3</b> 계층적 군집화</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="http://henryquant.blogspot.com/" target="blank">Henry's Quantopia</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">금융 데이터 사이언스</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="knn과-svm" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> KNN과 SVM</h1>
<p>대표적인 분류모형인 KNN과 SVM에 대해 알아보도록 하겠습니다.</p>
<div id="knn" class="section level2">
<h2><span class="header-section-number">5.1</span> KNN</h2>
<p>KNN 방법은 가장 가까운 점들, 즉 최근접 이웃들을 들여다보고 적합한 클래스를 결정하는 것입니다. <span class="math inline">\(K\)</span>는 알고리즘이 얼마나 많은 이웃을 검사해야 하는지를 정하는 값이며, 만일 <span class="math inline">\(K=5\)</span>였다면 5개의 가장 가까운 점들을 검사할 것입니다.</p>
<p><img src="images/knn.png" width="50%" style="display: block; margin: auto;" /></p>
<p>새로운 데이터가 들어온 경우, <span class="math inline">\(K=3\)</span> 에서는 주위 3개 데이터를 바탕으로 Class B라 판단합니다. 그러나 <span class="math inline">\(K=7\)</span> 에서는 주위 7개 데이터를 바탕으로 Class A라 판단합니다.</p>
</div>
<div id="svm" class="section level2">
<h2><span class="header-section-number">5.2</span> SVM</h2>
<p><img src="images/svm.png" width="50%" style="display: block; margin: auto;" /></p>
<p>SVM은 두 개의 데이터 그룹을 가장 잘 나누는 분류기를 찾는 방법입니다. 이 중 관찰값과 Margin이 만나는 부분을 Support Vector라 하며, 두 그룹 가운데의 음영부분(Margin)을 최대화 하는 선을 찾습니다. 일부 데이터의 경우 그룹을 완벽하게 분할할 수 없으므로 약간의 오류를 허용하며, wider margin과 lower total error penalty 간의 트레이드 오프를 최적화한 것을 Soft Margin Classification이라 합니다.</p>
</div>
<div id="데이터-불러오기-및-편집-2" class="section level2">
<h2><span class="header-section-number">5.3</span> 데이터 불러오기 및 편집</h2>
<p>국립 당뇨, 소화기 및 신장병 연구소에서 수집한 데이터를 사용하며, 532개 관찰값과 8개의 입력 피처 그리고 출력은 Y/N 을 갖습니다. 우리가 할 일은 인구 집단에서 당뇨를 앓거나 당뇨 위험 인자를 갖고 있는 개인들의 자료를 검사하고 당뇨병을 예측하는 것입니다.</p>
<p>MASS 패키지의 <code>Pima.tr</code>과 <code>Pima.te</code> 데이터를 사용하도록 합니다.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb147-1" data-line-number="1"><span class="kw">library</span>(e1071) <span class="co"># SVM</span></a>
<a class="sourceLine" id="cb147-2" data-line-number="2"><span class="kw">library</span>(MASS)</a>
<a class="sourceLine" id="cb147-3" data-line-number="3"></a>
<a class="sourceLine" id="cb147-4" data-line-number="4"><span class="kw">data</span>(Pima.tr)</a>
<a class="sourceLine" id="cb147-5" data-line-number="5"><span class="kw">str</span>(Pima.tr)</a></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    200 obs. of  8 variables:
##  $ npreg: int  5 7 5 0 0 5 3 1 3 2 ...
##  $ glu  : int  86 195 77 165 107 97 83 193 142 128 ...
##  $ bp   : int  68 70 82 76 60 76 58 50 80 78 ...
##  $ skin : int  28 33 41 43 25 27 31 16 15 37 ...
##  $ bmi  : num  30.2 25.1 35.8 47.9 26.4 35.6 34.3 25.9 32.4 43.3 ...
##  $ ped  : num  0.364 0.163 0.156 0.259 0.133 ...
##  $ age  : int  24 55 35 26 23 52 25 24 63 31 ...
##  $ type : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 2 1 1 1 2 1 1 1 2 ...</code></pre>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb149-1" data-line-number="1"><span class="kw">data</span>(Pima.te)</a>
<a class="sourceLine" id="cb149-2" data-line-number="2"><span class="kw">str</span>(Pima.te)</a></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    332 obs. of  8 variables:
##  $ npreg: int  6 1 1 3 2 5 0 1 3 9 ...
##  $ glu  : int  148 85 89 78 197 166 118 103 126 119 ...
##  $ bp   : int  72 66 66 50 70 72 84 30 88 80 ...
##  $ skin : int  35 29 23 32 45 19 47 38 41 35 ...
##  $ bmi  : num  33.6 26.6 28.1 31 30.5 25.8 45.8 43.3 39.3 29 ...
##  $ ped  : num  0.627 0.351 0.167 0.248 0.158 0.587 0.551 0.183 0.704 0.263 ...
##  $ age  : int  50 31 21 26 53 51 31 33 27 29 ...
##  $ type : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 1 1 2 2 2 2 1 1 2 ...</code></pre>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb151-1" data-line-number="1">pima =<span class="st"> </span><span class="kw">rbind</span>(Pima.tr, Pima.te)</a></code></pre></div>
<p>각 피처는 다음과 같습니다.</p>
<ul>
<li>npreg: 임신 횟수</li>
<li>glu: 구강 포도당 내성 검사에서 혈장 포도당 농도 (혈당값)</li>
<li>bp: 확장기 혈압</li>
<li>Skin: 삼두근 피하 지방 두께</li>
<li>bmi: 체질량 지수</li>
<li>ped: 당뇨 가족력 함수</li>
<li>age: 연령</li>
<li>type: 당뇨병 여부, Yes 또는 No</li>
</ul>
<p>당뇨병 여부에 따라 피처들의 특성을 살펴보도록 합니다.</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb152-1" data-line-number="1"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb152-2" data-line-number="2"><span class="kw">library</span>(magrittr)</a>
<a class="sourceLine" id="cb152-3" data-line-number="3"><span class="kw">library</span>(tidyr)</a>
<a class="sourceLine" id="cb152-4" data-line-number="4"></a>
<a class="sourceLine" id="cb152-5" data-line-number="5">pima <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb152-6" data-line-number="6"><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>type) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb152-7" data-line-number="7"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> type, <span class="dt">y =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb152-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb152-9" data-line-number="9"><span class="st">  </span><span class="kw">facet_wrap</span>( <span class="op">~</span><span class="st"> </span>key, <span class="dt">scale =</span> <span class="st">&#39;free&#39;</span>)</a></code></pre></div>
<p><img src="05-KNN_SVM_files/figure-html/unnamed-chunk-5-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>모든 데이터의 스케일이 다르므로 표준화를 해주어야 합니다. 표준화 방법에는 크게 두가지 방법이 있습니다.</p>
<ul>
<li><p>최소-최대 정규화(min-max normalization): <span class="math inline">\(X_{normal} = \frac{X - min(x)}{max(x) - min(x)}\)</span></p></li>
<li><p>z-점수 표준화(z-score standardization): <span class="math inline">\(Z = \frac{X - \mu}{\sigma} = \frac{X - Mean(x)}{StdDev(x)}\)</span></p></li>
</ul>
<p>이 중 <code>scale()</code> 함수를 이용하여 z-점수 표준화를 해주도록 합니다.</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb153-1" data-line-number="1"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb153-2" data-line-number="2"></a>
<a class="sourceLine" id="cb153-3" data-line-number="3">pima.scale =<span class="st"> </span>pima <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb153-4" data-line-number="4"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span><span class="dv">8</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb153-5" data-line-number="5"><span class="st">  </span><span class="kw">scale</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb153-6" data-line-number="6"><span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb153-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">type =</span> pima<span class="op">$</span>type)</a>
<a class="sourceLine" id="cb153-8" data-line-number="8"></a>
<a class="sourceLine" id="cb153-9" data-line-number="9"><span class="kw">head</span>(pima.scale)</a></code></pre></div>
<pre><code>##     npreg     glu      bp    skin     bmi     ped     age type
## 1  0.4478 -1.1300 -0.2848 -0.1123 -0.3910 -0.4033 -0.7076   No
## 2  1.0516  2.3862 -0.1223  0.3628 -1.1321 -0.9867  2.1730  Yes
## 3  0.4478 -1.4204  0.8525  1.1229  0.4229 -1.0070  0.3146   No
## 4 -1.0619  1.4184  0.3651  1.3130  2.1813 -0.7081 -0.5217   No
## 5 -1.0619 -0.4526 -0.9346 -0.3974 -0.9432 -1.0738 -0.8005   No
## 6  0.4478 -0.7752  0.3651 -0.2074  0.3938 -0.3627  1.8943  Yes</code></pre>
<p>표준화된 데이터로 다시 그림을 나타내도록 합니다.</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb155-1" data-line-number="1">pima.scale <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb155-2" data-line-number="2"><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>type) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb155-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> type, <span class="dt">y =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb155-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb155-5" data-line-number="5"><span class="st">  </span><span class="kw">facet_wrap</span>( <span class="op">~</span><span class="st"> </span>key, <span class="dt">scale =</span> <span class="st">&#39;free&#39;</span>)</a></code></pre></div>
<p><img src="05-KNN_SVM_files/figure-html/unnamed-chunk-7-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>다음으로 각 피처 간 상관관계를 살펴보도록 합니다.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb156-1" data-line-number="1"><span class="kw">library</span>(corrplot)</a>
<a class="sourceLine" id="cb156-2" data-line-number="2"></a>
<a class="sourceLine" id="cb156-3" data-line-number="3">pima.scale <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb156-4" data-line-number="4"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>type ) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb156-5" data-line-number="5"><span class="st">  </span><span class="kw">cor</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb156-6" data-line-number="6"><span class="st">  </span><span class="kw">corrplot.mixed</span>()</a></code></pre></div>
<p><img src="05-KNN_SVM_files/figure-html/unnamed-chunk-8-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>npreg와 age, skin과 bmi는 상관관계가 높은 편이지만, 제대로 훈련되고 하이퍼 파라미터가 제대로 조정되었을 경우 이런 다중 공선성은 대체로 분류 방법에서는 문제가 되지 않습니다. 트레이딩 셋과 테스트 셋으로 데이터를 나누기 전에 라벨 피처의 비율을 점검하도록 합니다.</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb157-1" data-line-number="1"><span class="kw">prop.table</span>(<span class="kw">table</span>(pima.scale<span class="op">$</span>type))</a></code></pre></div>
<pre><code>## 
##     No    Yes 
## 0.6673 0.3327</code></pre>
<p>No와 Yes의 비중이 대략 7:3 이므로 트레이딩 세트와 테스트 세트를 70/30 비율로 가르도록 합니다.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb159-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">502</span>)</a>
<a class="sourceLine" id="cb159-2" data-line-number="2">ind =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">2</span>, <span class="kw">nrow</span>(pima.scale), <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.7</span>, <span class="fl">0.3</span>))</a>
<a class="sourceLine" id="cb159-3" data-line-number="3">train =<span class="st"> </span>pima.scale[ind <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, ]</a>
<a class="sourceLine" id="cb159-4" data-line-number="4">test =<span class="st"> </span>pima.scale[ind <span class="op">==</span><span class="st"> </span><span class="dv">2</span>, ]</a>
<a class="sourceLine" id="cb159-5" data-line-number="5"></a>
<a class="sourceLine" id="cb159-6" data-line-number="6"><span class="kw">str</span>(train)</a></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    385 obs. of  8 variables:
##  $ npreg: num  0.448 0.448 -0.156 -0.76 -0.156 ...
##  $ glu  : num  -1.42 -0.775 -1.227 2.322 0.676 ...
##  $ bp   : num  0.852 0.365 -1.097 -1.747 0.69 ...
##  $ skin : num  1.123 -0.207 0.173 -1.253 -1.348 ...
##  $ bmi  : num  0.4229 0.3938 0.2049 -1.0159 -0.0712 ...
##  $ ped  : num  -1.007 -0.363 -0.485 0.441 -0.879 ...
##  $ age  : num  0.315 1.894 -0.615 -0.708 2.916 ...
##  $ type : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 2 1 1 1 2 2 1 1 1 ...</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb161-1" data-line-number="1"><span class="kw">str</span>(test)</a></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    147 obs. of  8 variables:
##  $ npreg: num  0.448 1.052 -1.062 -1.062 -0.458 ...
##  $ glu  : num  -1.13 2.386 1.418 -0.453 0.225 ...
##  $ bp   : num  -0.285 -0.122 0.365 -0.935 0.528 ...
##  $ skin : num  -0.112 0.363 1.313 -0.397 0.743 ...
##  $ bmi  : num  -0.391 -1.132 2.181 -0.943 1.513 ...
##  $ ped  : num  -0.403 -0.987 -0.708 -1.074 2.093 ...
##  $ age  : num  -0.7076 2.173 -0.5217 -0.8005 -0.0571 ...
##  $ type : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 2 1 1 2 1 2 1 1 1 ...</code></pre>
<p>데이터 점들의 거리 또는 근접 정도를 계산할때는 디폴트로 유클리디안 거리를 사용합니다. 이는 단순히 두 점 A와 B 사이의 직선 거리를 나타냅니다.</p>
<p><span class="math display">\[Euclidean\ Distance(A, B) = \sqrt{\sum_{i=1}^{n}(p_i - q_i)^2}\]</span></p>
<p>이는 피처를 측정할 때 사용한 스케일에 매우 종속적이므로 <strong>스케일을 표준화하는 일은 매우 중요합니다.</strong></p>
<div id="knn-1" class="section level3">
<h3><span class="header-section-number">5.3.1</span> KNN</h3>
<p>KNN 기법을 사용할 때는 가장 적절한 파라미터(K)를 선택하는 일이 매우 중요합니다. K를 구하기 위해 caret 패키지를 이용하며, 실험을 위해 K의 입력값을 위한 격자망을 2부터 20까지 1씩 증가하도록 만듭니다. <code>expand.grid()</code> 함수와 <code>seq()</code> 함수를 이용하면 쉽게 만들 수 있습니다.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb163-1" data-line-number="1">grid1 =<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">.k =</span> <span class="kw">seq</span>(<span class="dv">2</span>, <span class="dv">20</span>, <span class="dt">by =</span> <span class="dv">1</span>))</a></code></pre></div>
<p>K를 선택하기 위해 caret 패키지의 <code>trainControl()</code> 함수에 교차 검증법을 이용해 control 이라는 오브젝트를 만든다.</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb164-1" data-line-number="1"><span class="kw">library</span>(caret)</a>
<a class="sourceLine" id="cb164-2" data-line-number="2"></a>
<a class="sourceLine" id="cb164-3" data-line-number="3">control =<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&#39;cv&#39;</span>)</a></code></pre></div>
<p>caret 패키지의 <code>train()</code> 함수를 이용해 최적의 K 값을 구하는 오브젝트를 생성한다.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb165-1" data-line-number="1">knn.train =<span class="st"> </span><span class="kw">train</span>(type <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train,</a>
<a class="sourceLine" id="cb165-2" data-line-number="2">                  <span class="dt">method =</span> <span class="st">&#39;knn&#39;</span>, </a>
<a class="sourceLine" id="cb165-3" data-line-number="3">                  <span class="dt">trControl =</span> control,</a>
<a class="sourceLine" id="cb165-4" data-line-number="4">                  <span class="dt">tuneGrid =</span> grid1)</a>
<a class="sourceLine" id="cb165-5" data-line-number="5"></a>
<a class="sourceLine" id="cb165-6" data-line-number="6"><span class="kw">print</span>(knn.train)</a></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 385 samples
##   7 predictor
##   2 classes: &#39;No&#39;, &#39;Yes&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 345, 347, 347, 347, 347, 346, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy  Kappa 
##    2  0.7357    0.3684
##    3  0.7692    0.4352
##    4  0.7510    0.3987
##    5  0.7615    0.4066
##    6  0.7614    0.4140
##    7  0.7589    0.4042
##    8  0.7693    0.4277
##    9  0.7745    0.4372
##   10  0.7720    0.4360
##   11  0.7667    0.4194
##   12  0.7799    0.4478
##   13  0.7691    0.4133
##   14  0.7847    0.4587
##   15  0.7848    0.4555
##   16  0.7797    0.4391
##   17  0.7795    0.4416
##   18  0.7692    0.4105
##   19  0.7746    0.4255
##   20  0.7615    0.3998
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 15.</code></pre>
<p>위의 오브젝트를 호출하면 최적의 K가 출력됩니다. 최적의 K는 15이며, 이 때 정확도는 0.7795 입니다.</p>
<p>이제 위 모형을 class 패키지의 <code>knn()</code> 함수를 활용하여 테스트 데이터에 적용합니다. 해당 함수는 <code>knn(train, test, cl(training set), k)</code> 형태로 입력합니다.</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb167-1" data-line-number="1"><span class="kw">library</span>(class)</a>
<a class="sourceLine" id="cb167-2" data-line-number="2"></a>
<a class="sourceLine" id="cb167-3" data-line-number="3">knn.test =<span class="st"> </span><span class="kw">knn</span>(train[, <span class="dv">-8</span>], test[, <span class="dv">-8</span>], train[, <span class="dv">8</span>], <span class="dt">k =</span> <span class="dv">15</span>)</a>
<a class="sourceLine" id="cb167-4" data-line-number="4"><span class="kw">print</span>(knn.test)</a></code></pre></div>
<pre><code>##   [1] No  Yes No  No  No  Yes Yes No  No  No  Yes No  No  Yes No  No  Yes No 
##  [19] No  Yes No  No  No  No  Yes No  No  No  No  Yes No  No  No  Yes No  Yes
##  [37] No  No  No  No  No  No  Yes Yes Yes No  No  No  No  No  No  No  No  No 
##  [55] Yes Yes No  No  Yes No  Yes Yes Yes No  No  No  No  No  No  No  No  No 
##  [73] No  No  Yes No  Yes No  No  Yes Yes No  No  No  Yes No  No  No  No  No 
##  [91] No  No  No  Yes Yes No  No  No  No  No  No  No  No  No  No  No  No  No 
## [109] No  Yes Yes Yes No  Yes No  No  Yes No  Yes No  Yes No  Yes No  Yes Yes
## [127] No  No  Yes No  Yes No  No  No  No  No  No  Yes No  No  No  Yes No  Yes
## [145] Yes No  Yes
## Levels: No Yes</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb169-1" data-line-number="1">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(knn.test, test<span class="op">$</span>type)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction No Yes
##        No  76  27
##        Yes 17  27
##                                        
##                Accuracy : 0.701        
##                  95% CI : (0.62, 0.773)
##     No Information Rate : 0.633        
##     P-Value [Acc &gt; NIR] : 0.0505       
##                                        
##                   Kappa : 0.33         
##                                        
##  Mcnemar&#39;s Test P-Value : 0.1748       
##                                        
##             Sensitivity : 0.817        
##             Specificity : 0.500        
##          Pos Pred Value : 0.738        
##          Neg Pred Value : 0.614        
##              Prevalence : 0.633        
##          Detection Rate : 0.517        
##    Detection Prevalence : 0.701        
##       Balanced Accuracy : 0.659        
##                                        
##        &#39;Positive&#39; Class : No           
## </code></pre>
<p>정확도가 0.7007로써, 기존 트레이닝 셋의 정확도인 0.7795에 비해 다소 감소하였습니다.</p>
</div>
<div id="svm-1" class="section level3">
<h3><span class="header-section-number">5.3.2</span> SVM</h3>
<p>SVM 모형화를 위해서는 e1071 패키지의 <code>tune.svm()</code> 함수를 이용하도록 합니다.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb171-1" data-line-number="1"><span class="kw">library</span>(e1071)</a>
<a class="sourceLine" id="cb171-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb171-3" data-line-number="3"></a>
<a class="sourceLine" id="cb171-4" data-line-number="4">linear.tune =<span class="st"> </span><span class="kw">tune.svm</span>(type <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train,</a>
<a class="sourceLine" id="cb171-5" data-line-number="5">                       <span class="dt">kernel =</span> <span class="st">&#39;linear&#39;</span>,</a>
<a class="sourceLine" id="cb171-6" data-line-number="6">                       <span class="dt">cost =</span> <span class="kw">c</span>(<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="dv">01</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>))</a>
<a class="sourceLine" id="cb171-7" data-line-number="7"></a>
<a class="sourceLine" id="cb171-8" data-line-number="8"><span class="kw">summary</span>(linear.tune)</a></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  cost
##  0.01
## 
## - best performance: 0.2 
## 
## - Detailed performance results:
##     cost  error dispersion
## 1  0.001 0.3192    0.04699
## 2  0.010 0.2000    0.04579
## 3  1.000 0.2076    0.06253
## 4  1.000 0.2076    0.06253
## 5  5.000 0.2103    0.06322
## 6 10.000 0.2103    0.06322</code></pre>
<p>cost는 데이터를 잘못 분류하는 선을 긋게 될 경우 얼마만큼의 비용을 지불할 것인지를 지정합니다. SVM은 1) 데이터를 한 가운데로 얼마나 잘 나누는지와 2) 잘못 구분한 점으로 인한 비용의 합을 최소화하는 선을 찾습니다. 결과적으로 SVM은 cost를 사용해 과적합 정도를 조절하게 됩니다.</p>
<p>위 예제에서 최적의 cost 함수는 0.01로 나타났고, 분류 오류 비율은 대략 20% 정도입니다.</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb173-1" data-line-number="1">best.linear =<span class="st"> </span>linear.tune<span class="op">$</span>best.model</a>
<a class="sourceLine" id="cb173-2" data-line-number="2">tune.test =<span class="st"> </span><span class="kw">predict</span>(best.linear, <span class="dt">newdata =</span> test)</a>
<a class="sourceLine" id="cb173-3" data-line-number="3"></a>
<a class="sourceLine" id="cb173-4" data-line-number="4">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(tune.test, test<span class="op">$</span>type)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction No Yes
##        No  82  24
##        Yes 11  30
##                                         
##                Accuracy : 0.762         
##                  95% CI : (0.685, 0.828)
##     No Information Rate : 0.633         
##     P-Value [Acc &gt; NIR] : 0.000562      
##                                         
##                   Kappa : 0.461         
##                                         
##  Mcnemar&#39;s Test P-Value : 0.042522      
##                                         
##             Sensitivity : 0.882         
##             Specificity : 0.556         
##          Pos Pred Value : 0.774         
##          Neg Pred Value : 0.732         
##              Prevalence : 0.633         
##          Detection Rate : 0.558         
##    Detection Prevalence : 0.721         
##       Balanced Accuracy : 0.719         
##                                         
##        &#39;Positive&#39; Class : No            
## </code></pre>
<p>테스트 셋을 대상으로 정확도가 0.7619로써 knn 대비 약간 높은 정확도를 보입니다.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ridge-lasso.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="cart.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
