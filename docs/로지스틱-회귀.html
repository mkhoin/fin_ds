<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 로지스틱 회귀 | 금융 데이터 사이언스</title>
  <meta name="description" content="Chapter 3 로지스틱 회귀 | 금융 데이터 사이언스" />
  <meta name="generator" content="bookdown 0.15 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 로지스틱 회귀 | 금융 데이터 사이언스" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 로지스틱 회귀 | 금융 데이터 사이언스" />
  
  
  

<meta name="author" content="이현열" />


<meta name="date" content="2019-11-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="회귀분석.html"/>
<link rel="next" href="ridge-lasso.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">금융 데이터 사이언스</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#사용-패키지"><i class="fa fa-check"></i>사용 패키지</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="머신러닝이란.html"><a href="머신러닝이란.html"><i class="fa fa-check"></i><b>1</b> 머신러닝이란?</a><ul>
<li class="chapter" data-level="1.1" data-path="머신러닝이란.html"><a href="머신러닝이란.html#지도학습supervised-learning"><i class="fa fa-check"></i><b>1.1</b> 지도학습(Supervised Learning)</a></li>
<li class="chapter" data-level="1.2" data-path="머신러닝이란.html"><a href="머신러닝이란.html#비지도학습unsupervised-learning"><i class="fa fa-check"></i><b>1.2</b> 비지도학습(Unsupervised Learning)</a></li>
<li class="chapter" data-level="1.3" data-path="머신러닝이란.html"><a href="머신러닝이란.html#딥러닝-강화학습reinforcement-learning"><i class="fa fa-check"></i><b>1.3</b> 딥러닝 / 강화학습(Reinforcement Learning)</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="회귀분석.html"><a href="회귀분석.html"><i class="fa fa-check"></i><b>2</b> 회귀분석</a><ul>
<li class="chapter" data-level="2.1" data-path="회귀분석.html"><a href="회귀분석.html#상관관계-이해하기"><i class="fa fa-check"></i><b>2.1</b> 상관관계 이해하기</a></li>
<li class="chapter" data-level="2.2" data-path="회귀분석.html"><a href="회귀분석.html#회귀의-이해"><i class="fa fa-check"></i><b>2.2</b> 회귀의 이해</a><ul>
<li class="chapter" data-level="2.2.1" data-path="회귀분석.html"><a href="회귀분석.html#보통-최소-제곱ols-추정"><i class="fa fa-check"></i><b>2.2.1</b> 보통 최소 제곱(OLS) 추정</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="회귀분석.html"><a href="회귀분석.html#단변량-회귀분석"><i class="fa fa-check"></i><b>2.3</b> 단변량 회귀분석</a><ul>
<li class="chapter" data-level="2.3.1" data-path="회귀분석.html"><a href="회귀분석.html#챌린저-호-데이터"><i class="fa fa-check"></i><b>2.3.1</b> 챌린저 호 데이터</a></li>
<li class="chapter" data-level="2.3.2" data-path="회귀분석.html"><a href="회귀분석.html#미국-와이오밍-주-용출량-예측"><i class="fa fa-check"></i><b>2.3.2</b> 미국 와이오밍 주 용출량 예측</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="회귀분석.html"><a href="회귀분석.html#다변량-회귀분석"><i class="fa fa-check"></i><b>2.4</b> 다변량 회귀분석</a><ul>
<li class="chapter" data-level="2.4.1" data-path="회귀분석.html"><a href="회귀분석.html#다이아몬드-데이터"><i class="fa fa-check"></i><b>2.4.1</b> 다이아몬드 데이터</a></li>
<li class="chapter" data-level="2.4.2" data-path="회귀분석.html"><a href="회귀분석.html#캘리포니아-물-가용량"><i class="fa fa-check"></i><b>2.4.2</b> 캘리포니아 물 가용량</a></li>
<li class="chapter" data-level="2.4.3" data-path="회귀분석.html"><a href="회귀분석.html#최적화를-통한-변수-선택"><i class="fa fa-check"></i><b>2.4.3</b> 최적화를 통한 변수 선택</a></li>
<li class="chapter" data-level="2.4.4" data-path="회귀분석.html"><a href="회귀분석.html#robustness-check"><i class="fa fa-check"></i><b>2.4.4</b> Robustness Check</a></li>
<li class="chapter" data-level="2.4.5" data-path="회귀분석.html"><a href="회귀분석.html#실제와-예측간의-차이"><i class="fa fa-check"></i><b>2.4.5</b> 실제와 예측간의 차이</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="회귀분석.html"><a href="회귀분석.html#다른-고려사항"><i class="fa fa-check"></i><b>2.5</b> 다른 고려사항</a><ul>
<li class="chapter" data-level="2.5.1" data-path="회귀분석.html"><a href="회귀분석.html#질적-피처"><i class="fa fa-check"></i><b>2.5.1</b> 질적 피처</a></li>
<li class="chapter" data-level="2.5.2" data-path="회귀분석.html"><a href="회귀분석.html#상호작용-항"><i class="fa fa-check"></i><b>2.5.2</b> 상호작용 항</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html"><i class="fa fa-check"></i><b>3</b> 로지스틱 회귀</a><ul>
<li class="chapter" data-level="3.1" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#오즈비"><i class="fa fa-check"></i><b>3.1</b> 오즈비</a></li>
<li class="chapter" data-level="3.2" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#로지스틱-회귀-1"><i class="fa fa-check"></i><b>3.2</b> 로지스틱 회귀</a></li>
<li class="chapter" data-level="3.3" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#입학-데이터-분석"><i class="fa fa-check"></i><b>3.3</b> 입학 데이터 분석</a></li>
<li class="chapter" data-level="3.4" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#위스콘신-유방암-데이터"><i class="fa fa-check"></i><b>3.4</b> 위스콘신 유방암 데이터</a><ul>
<li class="chapter" data-level="3.4.1" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#데이터-불러오기-및-편집"><i class="fa fa-check"></i><b>3.4.1</b> 데이터 불러오기 및 편집</a></li>
<li class="chapter" data-level="3.4.2" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#데이터-나누기"><i class="fa fa-check"></i><b>3.4.2</b> 데이터 나누기</a></li>
<li class="chapter" data-level="3.4.3" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#모형화"><i class="fa fa-check"></i><b>3.4.3</b> 모형화</a></li>
<li class="chapter" data-level="3.4.4" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#테스트-셋에-적용"><i class="fa fa-check"></i><b>3.4.4</b> 테스트 셋에 적용</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#교차검증을-포함한-로지스틱-회귀"><i class="fa fa-check"></i><b>3.5</b> 교차검증을 포함한 로지스틱 회귀</a></li>
<li class="chapter" data-level="3.6" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#bic-기준-최적의-피처-선택"><i class="fa fa-check"></i><b>3.6</b> BIC 기준 최적의 피처 선택</a></li>
<li class="chapter" data-level="3.7" data-path="로지스틱-회귀.html"><a href="로지스틱-회귀.html#roc"><i class="fa fa-check"></i><b>3.7</b> ROC</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ridge-lasso.html"><a href="ridge-lasso.html"><i class="fa fa-check"></i><b>4</b> RIDGE &amp; LASSO</a><ul>
<li class="chapter" data-level="4.1" data-path="ridge-lasso.html"><a href="ridge-lasso.html#규제화"><i class="fa fa-check"></i><b>4.1</b> 규제화</a><ul>
<li class="chapter" data-level="4.1.1" data-path="ridge-lasso.html"><a href="ridge-lasso.html#규제화의-종류"><i class="fa fa-check"></i><b>4.1.1</b> 규제화의 종류</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ridge-lasso.html"><a href="ridge-lasso.html#전립선암-데이터-분석"><i class="fa fa-check"></i><b>4.2</b> 전립선암 데이터 분석</a><ul>
<li class="chapter" data-level="4.2.1" data-path="ridge-lasso.html"><a href="ridge-lasso.html#데이터-불러오기-및-편집-1"><i class="fa fa-check"></i><b>4.2.1</b> 데이터 불러오기 및 편집</a></li>
<li class="chapter" data-level="4.2.2" data-path="ridge-lasso.html"><a href="ridge-lasso.html#데이터-나누기-1"><i class="fa fa-check"></i><b>4.2.2</b> 데이터 나누기</a></li>
<li class="chapter" data-level="4.2.3" data-path="ridge-lasso.html"><a href="ridge-lasso.html#모형화-1"><i class="fa fa-check"></i><b>4.2.3</b> 모형화</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="knn과-svm.html"><a href="knn과-svm.html"><i class="fa fa-check"></i><b>5</b> KNN과 SVM</a><ul>
<li class="chapter" data-level="5.1" data-path="knn과-svm.html"><a href="knn과-svm.html#knn"><i class="fa fa-check"></i><b>5.1</b> KNN</a></li>
<li class="chapter" data-level="5.2" data-path="knn과-svm.html"><a href="knn과-svm.html#svm"><i class="fa fa-check"></i><b>5.2</b> SVM</a></li>
<li class="chapter" data-level="5.3" data-path="knn과-svm.html"><a href="knn과-svm.html#데이터-불러오기-및-편집-2"><i class="fa fa-check"></i><b>5.3</b> 데이터 불러오기 및 편집</a><ul>
<li class="chapter" data-level="5.3.1" data-path="knn과-svm.html"><a href="knn과-svm.html#knn-1"><i class="fa fa-check"></i><b>5.3.1</b> KNN</a></li>
<li class="chapter" data-level="5.3.2" data-path="knn과-svm.html"><a href="knn과-svm.html#svm-1"><i class="fa fa-check"></i><b>5.3.2</b> SVM</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="cart.html"><a href="cart.html"><i class="fa fa-check"></i><b>6</b> CART</a><ul>
<li class="chapter" data-level="6.1" data-path="cart.html"><a href="cart.html#의사결정나무"><i class="fa fa-check"></i><b>6.1</b> 의사결정나무</a><ul>
<li class="chapter" data-level="6.1.1" data-path="cart.html"><a href="cart.html#랜덤-포레스트"><i class="fa fa-check"></i><b>6.1.1</b> 랜덤 포레스트</a></li>
<li class="chapter" data-level="6.1.2" data-path="cart.html"><a href="cart.html#익스트림-그레디언트-부스트-기법-xgboost"><i class="fa fa-check"></i><b>6.1.2</b> 익스트림 그레디언트 부스트 기법 (XGboost)</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="cart.html"><a href="cart.html#회귀-트리"><i class="fa fa-check"></i><b>6.2</b> 회귀 트리</a><ul>
<li class="chapter" data-level="6.2.1" data-path="cart.html"><a href="cart.html#데이터-불러오기-및-편집-3"><i class="fa fa-check"></i><b>6.2.1</b> 데이터 불러오기 및 편집</a></li>
<li class="chapter" data-level="6.2.2" data-path="cart.html"><a href="cart.html#모형화-2"><i class="fa fa-check"></i><b>6.2.2</b> 모형화</a></li>
<li class="chapter" data-level="6.2.3" data-path="cart.html"><a href="cart.html#프루닝가지치기"><i class="fa fa-check"></i><b>6.2.3</b> 프루닝(가지치기)</a></li>
<li class="chapter" data-level="6.2.4" data-path="cart.html"><a href="cart.html#랜덤-포레스트-회귀-트리"><i class="fa fa-check"></i><b>6.2.4</b> 랜덤 포레스트: 회귀 트리</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="cart.html"><a href="cart.html#분류-트리"><i class="fa fa-check"></i><b>6.3</b> 분류 트리</a><ul>
<li class="chapter" data-level="6.3.1" data-path="cart.html"><a href="cart.html#데이터-불러오기-및-편집-4"><i class="fa fa-check"></i><b>6.3.1</b> 데이터 불러오기 및 편집</a></li>
<li class="chapter" data-level="6.3.2" data-path="cart.html"><a href="cart.html#랜덤-포레스트-분류-트리"><i class="fa fa-check"></i><b>6.3.2</b> 랜덤 포레스트: 분류 트리</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="cart.html"><a href="cart.html#익스트림-그레디언트-부스트-기법-xgboost-1"><i class="fa fa-check"></i><b>6.4</b> 익스트림 그레디언트 부스트 기법 (XGboost)</a><ul>
<li class="chapter" data-level="6.4.1" data-path="cart.html"><a href="cart.html#데이터-불러오기-및-편집-5"><i class="fa fa-check"></i><b>6.4.1</b> 데이터 불러오기 및 편집</a></li>
<li class="chapter" data-level="6.4.2" data-path="cart.html"><a href="cart.html#랜덤-포레스트-1"><i class="fa fa-check"></i><b>6.4.2</b> 랜덤 포레스트</a></li>
<li class="chapter" data-level="6.4.3" data-path="cart.html"><a href="cart.html#xgboost-모형-만들기"><i class="fa fa-check"></i><b>6.4.3</b> XGboost 모형 만들기</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>7</b> PCA</a><ul>
<li class="chapter" data-level="7.1" data-path="pca.html"><a href="pca.html#주성분분석pca"><i class="fa fa-check"></i><b>7.1</b> 주성분분석(PCA)</a></li>
<li class="chapter" data-level="7.2" data-path="pca.html"><a href="pca.html#iris-데이터-분석"><i class="fa fa-check"></i><b>7.2</b> iris 데이터 분석</a><ul>
<li class="chapter" data-level="7.2.1" data-path="pca.html"><a href="pca.html#데이터-불러오기"><i class="fa fa-check"></i><b>7.2.1</b> 데이터 불러오기</a></li>
<li class="chapter" data-level="7.2.2" data-path="pca.html"><a href="pca.html#모형화-3"><i class="fa fa-check"></i><b>7.2.2</b> 모형화</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="pca.html"><a href="pca.html#북미-프로-아이스하키-리그-데이터-분석"><i class="fa fa-check"></i><b>7.3</b> 북미 프로 아이스하키 리그 데이터 분석</a><ul>
<li class="chapter" data-level="7.3.1" data-path="pca.html"><a href="pca.html#데이터-불러오기-1"><i class="fa fa-check"></i><b>7.3.1</b> 데이터 불러오기</a></li>
<li class="chapter" data-level="7.3.2" data-path="pca.html"><a href="pca.html#성분-추출"><i class="fa fa-check"></i><b>7.3.2</b> 성분 추출</a></li>
<li class="chapter" data-level="7.3.3" data-path="pca.html"><a href="pca.html#직각-회전과-해석"><i class="fa fa-check"></i><b>7.3.3</b> 직각 회전과 해석</a></li>
<li class="chapter" data-level="7.3.4" data-path="pca.html"><a href="pca.html#요인-점수-생성"><i class="fa fa-check"></i><b>7.3.4</b> 요인 점수 생성</a></li>
<li class="chapter" data-level="7.3.5" data-path="pca.html"><a href="pca.html#회귀-분석"><i class="fa fa-check"></i><b>7.3.5</b> 회귀 분석</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="http://henryquant.blogspot.com/" target="blank">Henry's Quantopia</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">금융 데이터 사이언스</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="로지스틱-회귀" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> 로지스틱 회귀</h1>
<div id="오즈비" class="section level2">
<h2><span class="header-section-number">3.1</span> 오즈비</h2>
<p>오즈는 성공할 확률이 실패할 확률의 몇 배인지를 나타내는 것으로써, <span class="math inline">\(Probability(Y) / 1 - (Probability(Y))\)</span> 공식을 통해 계산됩니다. 예를 들어, 브라질이 월드컵 경기에서 이길 확률이 20%라면, 오즈는 <span class="math inline">\(0.2 / (1-0.2) = 0.25\)</span>가 되고, 1대 4의 승산입니다. 오즈를 확률로 역변환하려면 오즈를 <span class="math inline">\(1 + (오즈)\)</span>로 나누며, 앞의 예에서는 <span class="math inline">\(0.25 / (1+0.25) = 0.2\)</span>, 즉 20%가 됩니다.</p>
<p>만일 독일이 우승할 오즈가 0.18, 브라질이 우승할 오즈가 0.25인 경우 둘 간의 오즈를 오즈비를 이용해 비교할 수 있습니다. 브라질이 독일 대비 월드컵에서 우승할 확률은 0.25 / 0.18 = 1.39 입니다.</p>
</div>
<div id="로지스틱-회귀-1" class="section level2">
<h2><span class="header-section-number">3.2</span> 로지스틱 회귀</h2>
<p>결과가 이항 혹은 다항 범주일 경우, 관찰값이 출력 변수의 특정 범주에 속할 확률을 예측해야 합니다. 이를 위해 기존 OLS 선형 회귀를 사용할 경우 매우 큰 측정 오차가 생길 수 있으며 편향된 결과를 낳습니다.</p>
<p>분류 문제는 0과 1 사이의 값을 갖는 확률로 가장 잘 모형화할 수 있습니다. 로지스틱 회귀와 선형 회귀의 관계는 로지스틱 회귀의 종속 변수를 로그 오즈, 즉 <span class="math inline">\(log(P(Y) / 1-P(Y))\)</span>로 표현하고 이 값이 <span class="math inline">\(a + bX\)</span>와 같음을 밝힘으로써 보일 수 있습니다. 이를 정리하면 다음과 같습니다.</p>
<p><span class="math display">\[log(\frac{P(Y)}{1-P(Y)}) = a + bX\]</span>
<span class="math display">\[\frac{P(Y)}{1-P(Y)} = e^{a + bX}\]</span>
<span class="math display">\[ P(Y) = \frac{e^{a + bX}}{1 + e^{a + bX}}  \]</span></p>
<p>위 <span class="math inline">\(P(Y)\)</span> 를 그래프로 나타내면 다음과 같다.</p>
<p><img src="03-logistic_files/figure-html/unnamed-chunk-2-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>즉 <span class="math inline">\(x\)</span>에 따른 <span class="math inline">\(y\)</span>의 확률이 0과 1 사이에 놓이게 됩니다.</p>
</div>
<div id="입학-데이터-분석" class="section level2">
<h2><span class="header-section-number">3.3</span> 입학 데이터 분석</h2>
<p>GRE, GPA, RANK가 입학(admission)에 어떤 영향을 주는지 로지스틱 회귀분석을 통해 분석하도록 하겠습니다.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb65-1" data-line-number="1">admission =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;https://stats.idre.ucla.edu/stat/data/binary.csv&quot;</span>)</a>
<a class="sourceLine" id="cb65-2" data-line-number="2"><span class="kw">head</span>(admission)</a></code></pre></div>
<pre><code>##   admit gre  gpa rank
## 1     0 380 3.61    3
## 2     1 660 3.67    3
## 3     1 800 4.00    1
## 4     1 640 3.19    4
## 5     0 520 2.93    4
## 6     1 760 3.00    2</code></pre>
<p><code>glm()</code> 함수를 이용하여 로지스틱 회귀분석을 실시합니다.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" data-line-number="1">ad.logit =<span class="st"> </span><span class="kw">glm</span>(admit <span class="op">~</span><span class="st"> </span>., <span class="dt">family =</span> binomial, <span class="dt">data =</span> admission)</a>
<a class="sourceLine" id="cb67-2" data-line-number="2"><span class="kw">summary</span>(ad.logit)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = admit ~ ., family = binomial, data = admission)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.580  -0.885  -0.638   1.157   2.173  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -3.44955    1.13285   -3.05   0.0023 ** 
## gre          0.00229    0.00109    2.10   0.0356 *  
## gpa          0.77701    0.32748    2.37   0.0177 *  
## rank        -0.56003    0.12714   -4.40 0.000011 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 499.98  on 399  degrees of freedom
## Residual deviance: 459.44  on 396  degrees of freedom
## AIC: 467.4
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>모든 변수가 유의미한 결과를 보입니다. 로지스틱 회귀에서는 OLS와는 다르게 피처의 계수를 <span class="math inline">\(X\)</span>가 한 단위 변화할 때 <span class="math inline">\(Y\)</span>가 변화하는 양을 나타낸다고 해석할 수 없습니다. 로그 함수에서 <span class="math inline">\(\beta\)</span>라는 계수는 오즈비 <span class="math inline">\(e^\beta\)</span>로 변환해 해석해야 합니다.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" data-line-number="1"><span class="kw">exp</span>(<span class="kw">coef</span>(ad.logit))</a></code></pre></div>
<pre><code>## (Intercept)         gre         gpa        rank 
##     0.03176     1.00230     2.17497     0.57119</code></pre>
<p>오즈비는 피처가 한 단위 변했을 때 나타나는 결과의 오지로 해석할 수 있습니다. 만일 이 값이 1보다 크면 피처가 증가할 때 결과의 오즈도 증가하며, 1보다 작으면 피처가 증가할 때 결과의 오즈는 감소합니다.</p>
<p>위의 예에서 gre와 gpa는 로그 오즈를 증가시키지만, rank는 로그 오즈를 감소시킵니다.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" data-line-number="1">ad.probs =<span class="st"> </span>ad.logit<span class="op">$</span>fitted.values</a>
<a class="sourceLine" id="cb71-2" data-line-number="2">ad.probs =<span class="st"> </span><span class="kw">ifelse</span>(ad.probs <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</a></code></pre></div>
<p>회귀분석 결과의 fitted.values에는 확률이 저장되어 있으며, 해당 값이 0.5보다 크면 1, 그렇지 않으면 0로 변환해줍니다. 이를 실제 데이터와 비교해보도록 합니다.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb72-1" data-line-number="1"><span class="kw">table</span>(ad.probs, admission<span class="op">$</span>admit)</a></code></pre></div>
<pre><code>##         
## ad.probs   0   1
##        0 253  98
##        1  20  29</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" data-line-number="1"><span class="kw">prop.table</span>(<span class="kw">table</span>(ad.probs, admission<span class="op">$</span>admit))</a></code></pre></div>
<pre><code>##         
## ad.probs      0      1
##        0 0.6325 0.2450
##        1 0.0500 0.0725</code></pre>
<p>맞게 판단할 확률이 대략 70% 입니다.</p>
</div>
<div id="위스콘신-유방암-데이터" class="section level2">
<h2><span class="header-section-number">3.4</span> 위스콘신 유방암 데이터</h2>
<p>위스콘신 유방암 데이터를 통해 종양이 양성 혹은 악성인지에 대해 예측해보도록 하겠습니다. 해당 데이터는 MASS 패키지의 <code>biopsy</code> 이름으로 저장되어 있습니다.</p>
<div id="데이터-불러오기-및-편집" class="section level3">
<h3><span class="header-section-number">3.4.1</span> 데이터 불러오기 및 편집</h3>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" data-line-number="1"><span class="kw">library</span>(MASS)</a>
<a class="sourceLine" id="cb76-2" data-line-number="2"></a>
<a class="sourceLine" id="cb76-3" data-line-number="3"><span class="kw">data</span>(biopsy)</a>
<a class="sourceLine" id="cb76-4" data-line-number="4"><span class="kw">str</span>(biopsy)</a></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    699 obs. of  11 variables:
##  $ ID   : chr  &quot;1000025&quot; &quot;1002945&quot; &quot;1015425&quot; &quot;1016277&quot; ...
##  $ V1   : int  5 5 3 6 4 8 1 2 2 4 ...
##  $ V2   : int  1 4 1 8 1 10 1 1 1 2 ...
##  $ V3   : int  1 4 1 8 1 10 1 2 1 1 ...
##  $ V4   : int  1 5 1 1 3 8 1 1 1 1 ...
##  $ V5   : int  2 7 2 3 2 7 2 2 2 2 ...
##  $ V6   : int  1 10 2 4 1 10 10 1 1 1 ...
##  $ V7   : int  3 3 3 3 3 9 3 3 1 2 ...
##  $ V8   : int  1 2 1 7 1 7 1 1 1 1 ...
##  $ V9   : int  1 1 1 1 1 1 1 1 5 1 ...
##  $ class: Factor w/ 2 levels &quot;benign&quot;,&quot;malignant&quot;: 1 1 1 1 1 2 1 1 1 1 ...</code></pre>
<p>각 피처는 다음과 같습니다.</p>
<ul>
<li>ID: 표본의 코드 번호</li>
<li>V1: 두께</li>
<li>V2: 세포 크기의 균일성</li>
<li>V3: 세포 모양의 균일성</li>
<li>V4: 한계 부착력</li>
<li>V5: 단일 상피세포 크기</li>
<li>V6: 나핵(16개의 관찰값 결측)</li>
<li>V7: 특징 없는 염색질</li>
<li>V8: 정상 핵소체</li>
<li>V9: 분열</li>
<li>class: 종양의 진단의 결과, 양성 또는 악성. 우리가 예측하려는 결과</li>
</ul>
<p>피처명이 입력되어 있지 않으므로, 이를 입력해주도록 합니다.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" data-line-number="1">biopsy<span class="op">$</span>ID =<span class="st"> </span><span class="ot">NULL</span></a>
<a class="sourceLine" id="cb78-2" data-line-number="2"><span class="kw">names</span>(biopsy) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;thick&#39;</span>, <span class="st">&#39;u.size&#39;</span>, <span class="st">&#39;u.shape&#39;</span>, <span class="st">&#39;adhsn&#39;</span>, <span class="st">&#39;s.size&#39;</span>,</a>
<a class="sourceLine" id="cb78-3" data-line-number="3">                  <span class="st">&#39;nucl&#39;</span>, <span class="st">&#39;chrom&#39;</span>, <span class="st">&#39;n.nuc&#39;</span>, <span class="st">&#39;mit&#39;</span>, <span class="st">&#39;class&#39;</span>)</a>
<a class="sourceLine" id="cb78-4" data-line-number="4"></a>
<a class="sourceLine" id="cb78-5" data-line-number="5"><span class="kw">head</span>(biopsy)</a></code></pre></div>
<pre><code>##   thick u.size u.shape adhsn s.size nucl chrom n.nuc mit     class
## 1     5      1       1     1      2    1     3     1   1    benign
## 2     5      4       4     5      7   10     3     2   1    benign
## 3     3      1       1     1      2    2     3     1   1    benign
## 4     6      8       8     1      3    4     3     7   1    benign
## 5     4      1       1     3      2    1     3     1   1    benign
## 6     8     10      10     8      7   10     9     7   1 malignant</code></pre>
<p>다음으로 결측 관측치를 삭제 및 데이터를 변형해줍니다.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" data-line-number="1"><span class="kw">sum</span>(<span class="kw">is.na</span>(biopsy))</a></code></pre></div>
<pre><code>## [1] 16</code></pre>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" data-line-number="1">biopsy.v2 =<span class="st"> </span><span class="kw">na.omit</span>(biopsy)</a>
<a class="sourceLine" id="cb82-2" data-line-number="2">y =<span class="st"> </span><span class="kw">ifelse</span>(biopsy.v2<span class="op">$</span>class <span class="op">==</span><span class="st"> &#39;malignant&#39;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb82-3" data-line-number="3"><span class="kw">table</span>(y)</a></code></pre></div>
<pre><code>## y
##   0   1 
## 444 239</code></pre>
<p>총 16개의 na 데이터가 존재하며, <code>na.omit()</code> 함수를 통해 해당 데이터를 모두 지워주도록 합니다. 또한 예측변수 y에는 class가 malignant(악성)일 경우 1, 그렇지 않을 경우 0을 입력합니다.</p>
<p><code>gather()</code> 함수를 통해 테이블을 변경한 후, <code>ggplot()</code> 함수를 통해 각 class 별 피처들의 분포를 살펴보도록 합니다.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" data-line-number="1"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb84-2" data-line-number="2"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb84-3" data-line-number="3"><span class="kw">library</span>(tidyr)</a>
<a class="sourceLine" id="cb84-4" data-line-number="4"><span class="kw">library</span>(magrittr)</a>
<a class="sourceLine" id="cb84-5" data-line-number="5"></a>
<a class="sourceLine" id="cb84-6" data-line-number="6">biop.m =<span class="st"> </span>biopsy.v2 <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb84-7" data-line-number="7"><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>class)</a>
<a class="sourceLine" id="cb84-8" data-line-number="8"></a>
<a class="sourceLine" id="cb84-9" data-line-number="9">biop.m <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb84-10" data-line-number="10"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> class, <span class="dt">y =</span> value)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb84-11" data-line-number="11"><span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb84-12" data-line-number="12"><span class="st">  </span><span class="kw">facet_wrap</span>( <span class="op">~</span><span class="st"> </span>key)</a></code></pre></div>
<p><img src="03-logistic_files/figure-html/unnamed-chunk-11-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>다중공선성 확인을 위해 상관관계를 검사하도록 합니다.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" data-line-number="1"><span class="kw">library</span>(corrplot)</a>
<a class="sourceLine" id="cb85-2" data-line-number="2"></a>
<a class="sourceLine" id="cb85-3" data-line-number="3">bc =<span class="st"> </span>biopsy.v2 <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb85-4" data-line-number="4"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>class) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb85-5" data-line-number="5"><span class="st">  </span><span class="kw">cor</span>()</a>
<a class="sourceLine" id="cb85-6" data-line-number="6"></a>
<a class="sourceLine" id="cb85-7" data-line-number="7"><span class="kw">corrplot.mixed</span>(bc)</a></code></pre></div>
<p><img src="03-logistic_files/figure-html/unnamed-chunk-12-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>u.size와 u.shape 간 상관관계가 0.91로 다중공선성 문제가 두드러져 보입니다.</p>
</div>
<div id="데이터-나누기" class="section level3">
<h3><span class="header-section-number">3.4.2</span> 데이터 나누기</h3>
<p>기존에는 모든 데이터를 이용하여 모델을 훈련시켰습니다. 그러나 모델의 예측력을 평가하기 위해서는 모델링에 사용되지 않은 데이터와 평가하야 합니다. 이를 위해 트레이닝 및 테스트 세트로 나누도록 합니다. 일반적으로 트레이닝과 테스트 셋의 비율은 7:3 혹은 8:2로 합니다.</p>
<p><img src="images/data_split.png" width="50%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb86-2" data-line-number="2"></a>
<a class="sourceLine" id="cb86-3" data-line-number="3">ind =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">2</span>, <span class="kw">nrow</span>(biopsy.v2), <span class="dt">replace =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb86-4" data-line-number="4">             <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.7</span>, <span class="fl">0.3</span>))</a>
<a class="sourceLine" id="cb86-5" data-line-number="5"></a>
<a class="sourceLine" id="cb86-6" data-line-number="6">train =<span class="st"> </span>biopsy.v2[ind<span class="op">==</span><span class="dv">1</span>, ]</a>
<a class="sourceLine" id="cb86-7" data-line-number="7">test =<span class="st"> </span>biopsy.v2[ind<span class="op">==</span><span class="dv">2</span>, ]</a></code></pre></div>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" data-line-number="1"><span class="kw">prop.table</span>(<span class="kw">table</span>(train<span class="op">$</span>class))</a></code></pre></div>
<pre><code>## 
##    benign malignant 
##    0.6371    0.3629</code></pre>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb89-1" data-line-number="1"><span class="kw">prop.table</span>(<span class="kw">table</span>(test<span class="op">$</span>class))</a></code></pre></div>
<pre><code>## 
##    benign malignant 
##    0.6794    0.3206</code></pre>
<p><code>sample()</code> 을 통해 무작위 숫자를 7:3 비율로 생성한 후, train과 test 셋으로 나눠주도록 합니다. 그 후 각 데이터 셋의 종속변수의 비율을 확인해 7:3 비율과 비슷한지 확인합니다.</p>
</div>
<div id="모형화" class="section level3">
<h3><span class="header-section-number">3.4.3</span> 모형화</h3>
<p>먼저 모든 입력 변수로 로지스틱 모형을 만든 후 점차 줄여 나가며 최량 부분 집합을 생성하도록 합니다.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" data-line-number="1">full.fit =<span class="st"> </span><span class="kw">glm</span>(class <span class="op">~</span><span class="st"> </span>., <span class="dt">family =</span> binomial, <span class="dt">data =</span> train)</a>
<a class="sourceLine" id="cb91-2" data-line-number="2"><span class="kw">summary</span>(full.fit)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = class ~ ., family = binomial, data = train)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -3.340  -0.139  -0.072   0.032   2.356  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   -9.429      1.227   -7.68  1.6e-14 ***
## thick          0.525      0.160    3.28  0.00104 ** 
## u.size        -0.105      0.245   -0.43  0.66917    
## u.shape        0.280      0.253    1.11  0.26804    
## adhsn          0.309      0.174    1.78  0.07572 .  
## s.size         0.287      0.207    1.38  0.16702    
## nucl           0.406      0.121    3.34  0.00083 ***
## chrom          0.274      0.217    1.26  0.20801    
## n.nuc          0.224      0.137    1.63  0.10213    
## mit            0.430      0.339    1.27  0.20540    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 620.989  on 473  degrees of freedom
## Residual deviance:  78.373  on 464  degrees of freedom
## AIC: 98.37
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb93-1" data-line-number="1"><span class="kw">exp</span>(<span class="kw">coef</span>(full.fit)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(., <span class="dv">4</span>)</a></code></pre></div>
<pre><code>## (Intercept)       thick      u.size     u.shape       adhsn      s.size 
##      0.0001      1.6909      0.9007      1.3228      1.3615      1.3319 
##        nucl       chrom       n.nuc         mit 
##      1.5003      1.3148      1.2516      1.5367</code></pre>
<p>위 예제에서 u.size를 제외한 모든 피처가 로그 오즈를 증가시킵니다. 다음으로 다중공선성을 확인합니다.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" data-line-number="1"><span class="kw">library</span>(car)</a>
<a class="sourceLine" id="cb95-2" data-line-number="2"><span class="kw">vif</span>(full.fit)</a></code></pre></div>
<pre><code>##   thick  u.size u.shape   adhsn  s.size    nucl   chrom   n.nuc     mit 
##   1.235   3.249   2.830   1.302   1.636   1.373   1.523   1.343   1.060</code></pre>
<p>위의 값들 중 어느 것도 통계값이 5보다 크지 않으므로 공선성을 크게 문제가 되지 안습니다.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb97-1" data-line-number="1">train.probs =<span class="st"> </span>full.fit<span class="op">$</span>fitted.values</a>
<a class="sourceLine" id="cb97-2" data-line-number="2"><span class="kw">head</span>(train.probs)</a></code></pre></div>
<pre><code>##       1       3       6       7       9      10 
## 0.02053 0.01088 0.99993 0.08987 0.01379 0.00842</code></pre>
<p>확률을 선택한 후, 해당 값이 0.5보다 클 경우 1, 아닐 경우 0으로 구분합니다. 그 후 train 데이터의 class와 비교하여 예측 정확도를 비교해보도록 한다.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb99-1" data-line-number="1">train.bi =<span class="st"> </span><span class="kw">ifelse</span>(train.probs <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>()</a>
<a class="sourceLine" id="cb99-2" data-line-number="2">train.class =<span class="st"> </span><span class="kw">ifelse</span>(train<span class="op">$</span>class <span class="op">==</span><span class="st"> &#39;malignant&#39;</span>, <span class="dv">1</span>, <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>()</a>
<a class="sourceLine" id="cb99-3" data-line-number="3"></a>
<a class="sourceLine" id="cb99-4" data-line-number="4">true.ratio =<span class="st"> </span><span class="kw">prop.table</span>(<span class="kw">table</span>(train.bi, train.class))</a>
<a class="sourceLine" id="cb99-5" data-line-number="5"><span class="kw">print</span>(true.ratio[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>true.ratio[<span class="dv">2</span>,<span class="dv">2</span>])</a></code></pre></div>
<pre><code>## [1] 0.9684</code></pre>
<p>예측 정확도가 0.6203, 0.0169, 0.0148, 0.3481로 매우 높게 나타납니다.</p>
<div id="혼돈-행렬confusion-matrix-이해하기" class="section level4">
<h4><span class="header-section-number">3.4.3.1</span> 혼돈 행렬(Confusion Matrix) 이해하기</h4>
<p>혼돈 행렬은 예측 값이 실제 값과 일치하는지에 따라 여측을 범주화한 표입니다. 한 차원은 예측 값을 나타내고, 다른 차원은 실제값을 나타냅니다.</p>
<p>일반적으로 관심 있는 클래스를 positive 클래스, 다른 클래스들을 false 클래스라고 하며, 두 클래스의 관계는 네 종류의 범주 중 예측이 속하는 범주를 도표화한 2 X 2 혼동 행렬로 표현할 수 있습니다.</p>
<p><img src="images/confusion_matrix.png" width="50%" style="display: block; margin: auto;" /></p>
<p>각 항목의 설명은 다음과 같습니다.</p>
<ul>
<li>True Positive: 관심 클래스로 정확하게 분류</li>
<li>True Negative: 관심 클래스가 아닌 클래스로 정확하게 분류</li>
<li>False Positive: 관심 클래스로 부정확학 분류</li>
<li>False Negative: 관심 클래스가 아닌 클래스로 부정확하게 분류</li>
</ul>
<p>혼돈 행렬을 이용한 성능 측정에는 다음과 같은 값들이 있습니다.</p>
<ul>
<li><p><strong>정확도(Accuracy)</strong>: <span class="math inline">\(\frac{TP + TN}{TP + TN + FP + FN}\)</span>, True Positive과 True Negative의 횟수를 전체 예측 횟수로 나눈 값</p></li>
<li><p>오류율(Error rate): <span class="math inline">\(\frac{FP + FN}{TP + TN + FP + FN} = 1 - 정확도\)</span>, 부정확한 분류된 예시</p></li>
<li><p>재현율(Recall): <span class="math inline">\(\frac{TP}{TP + FN}\)</span>, True Postiive 개수를 전체 긍정 개수로 나누어 계산. 민감도(Sensitivity)로도 불림</p></li>
<li><p>특이도(Specificity, 참 부정률): <span class="math inline">\(\frac{TN}{TN + FP}\)</span>, True Negative의 개수를 전체 부정으로 나누어 계산</p></li>
<li><p>정밀도(Precision, 긍정 예측 값): <span class="math inline">\(\frac{TP}{TP + FP}\)</span>, 모델이 Positive로 예측할 때 예측이 얼마나 정확한지 여부</p></li>
<li><p>F 점수(F-score): <span class="math inline">\(\frac{2 \times 정밀도 \times 재현율}{재현율 + 정밀도} = \frac{2 \times TP}{2 \times TP + FP+ FN}\)</span>, 조화 평균을 이용하여 정밀도와 재현율을 결합</p></li>
</ul>
<p>혼돈 행렬은 caret 패키지의 <code>confusionMatrix(predict, truth)</code> 함수를 이용해 계산할 수 있습니다.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb101-1" data-line-number="1">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(train.bi, train.class)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 294   7
##          1   8 165
##                                         
##                Accuracy : 0.968         
##                  95% CI : (0.948, 0.982)
##     No Information Rate : 0.637         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.932         
##                                         
##  Mcnemar&#39;s Test P-Value : 1             
##                                         
##             Sensitivity : 0.974         
##             Specificity : 0.959         
##          Pos Pred Value : 0.977         
##          Neg Pred Value : 0.954         
##              Prevalence : 0.637         
##          Detection Rate : 0.620         
##    Detection Prevalence : 0.635         
##       Balanced Accuracy : 0.966         
##                                         
##        &#39;Positive&#39; Class : 0             
## </code></pre>
<p>정확도를 의미하는 <em>Accuracy</em>가 0.9684로 직접 계산한 값과 동일합니다.</p>
</div>
</div>
<div id="테스트-셋에-적용" class="section level3">
<h3><span class="header-section-number">3.4.4</span> 테스트 셋에 적용</h3>
<p>위 모형은 트레이닝 셋을 대상으로 만들어졌습니다. 따라서 모형에 포함되지 않은 데이터인 테스트 셋의 데이터를 대상으로 모델의 정확도를 구해보도록 합니다.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb103-1" data-line-number="1">test.probs =<span class="st"> </span><span class="kw">predict</span>(full.fit, <span class="dt">newdata =</span> test, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</a>
<a class="sourceLine" id="cb103-2" data-line-number="2"></a>
<a class="sourceLine" id="cb103-3" data-line-number="3">test.bi =<span class="st"> </span><span class="kw">ifelse</span>(test.probs <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>()</a>
<a class="sourceLine" id="cb103-4" data-line-number="4">test.class =<span class="st"> </span><span class="kw">ifelse</span>(test<span class="op">$</span>class <span class="op">==</span><span class="st"> &#39;malignant&#39;</span>, <span class="dv">1</span>, <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>()</a>
<a class="sourceLine" id="cb103-5" data-line-number="5"></a>
<a class="sourceLine" id="cb103-6" data-line-number="6">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(test.bi, test.class)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 139   2
##          1   3  65
##                                         
##                Accuracy : 0.976         
##                  95% CI : (0.945, 0.992)
##     No Information Rate : 0.679         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.945         
##                                         
##  Mcnemar&#39;s Test P-Value : 1             
##                                         
##             Sensitivity : 0.979         
##             Specificity : 0.970         
##          Pos Pred Value : 0.986         
##          Neg Pred Value : 0.956         
##              Prevalence : 0.679         
##          Detection Rate : 0.665         
##    Detection Prevalence : 0.675         
##       Balanced Accuracy : 0.975         
##                                         
##        &#39;Positive&#39; Class : 0             
## </code></pre>
<p><code>predict()</code> 함수의 newdata 인자에 test를 입력하여 확률을 계산한 후, 혼돈 행렬을 구하도록 합니다. 정확도가 0.9761로써 역시나 뛰어난 성과를 보입니다.</p>
</div>
</div>
<div id="교차검증을-포함한-로지스틱-회귀" class="section level2">
<h2><span class="header-section-number">3.5</span> 교차검증을 포함한 로지스틱 회귀</h2>
<p>K-폴드 교차검증은 데이터 세트를 같은 크기를 갖는 조각으로 K등분한 후, K-세트 중에 1개의 세트를 번갈아 제외하며 학습합니다.</p>
<p><img src="images/kfolds.png" width="50%" style="display: block; margin: auto;" /></p>
<p>bestglm 패키지를 이용하여 교차 검증을 이용한 로지스틱 회귀분석을 실행할 수 있습니다. 해당 패키지를 이용하기 위해서 결과값을 0과 1로 코드화할 필요가 있으며, 만일 변수형이 팩터 형태로 남아 있으면 작동이 되지 않습니다. 또한 결과값인 <span class="math inline">\(y\)</span>가 맨 마지막 컬럼에 위치해야 하며, 불필요한 컬럼은 삭제되어야 합니다.</p>
<p>이를 고려하여 새로운 데이터 테이블을 만들고, 교차 검증을 실시합니다.</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb105-1" data-line-number="1"><span class="kw">library</span>(bestglm)</a>
<a class="sourceLine" id="cb105-2" data-line-number="2">df =<span class="st"> </span>train <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb105-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">class =</span> <span class="kw">ifelse</span>(class <span class="op">==</span><span class="st"> &#39;malignant&#39;</span>, <span class="dv">1</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb105-4" data-line-number="4"></a>
<a class="sourceLine" id="cb105-5" data-line-number="5"><span class="kw">bestglm</span>(df, <span class="dt">IC =</span> <span class="st">&#39;CV&#39;</span>,</a>
<a class="sourceLine" id="cb105-6" data-line-number="6">        <span class="dt">CVArgs =</span> <span class="kw">list</span>(<span class="dt">Method =</span> <span class="st">&#39;HTF&#39;</span>, <span class="dt">K =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb105-7" data-line-number="7">                      <span class="dt">REP =</span> <span class="dv">1</span>), <span class="dt">family =</span> binomial)</a></code></pre></div>
<pre><code>## CV(K = 10, REP = 1)
## BICq equivalent for q in (0.0000716797006619085, 0.273173435514231)
## Best Model:
##             Estimate Std. Error z value  Pr(&gt;|z|)
## (Intercept)  -7.8147    0.90996  -8.588 8.855e-18
## thick         0.6188    0.14713   4.206 2.598e-05
## u.size        0.6582    0.15295   4.303 1.683e-05
## nucl          0.5726    0.09923   5.771 7.899e-09</code></pre>
<p>K = 10 개를 대상으로 교차 검증을 수행한 결과 최적의 변수가 선택되었습니다. 해당 변수만을 이용하여 다시 로지스틱 회귀분석을 실시합니다.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb107-1" data-line-number="1">reduce.fit =<span class="st"> </span><span class="kw">glm</span>(class <span class="op">~</span><span class="st"> </span>thick <span class="op">+</span><span class="st"> </span>u.size <span class="op">+</span><span class="st"> </span>nucl, <span class="dt">family =</span> binomial,</a>
<a class="sourceLine" id="cb107-2" data-line-number="2">                 <span class="dt">data =</span> train)</a>
<a class="sourceLine" id="cb107-3" data-line-number="3"><span class="kw">summary</span>(reduce.fit)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = class ~ thick + u.size + nucl, family = binomial, 
##     data = train)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -3.579  -0.181  -0.072   0.042   2.373  
## 
## Coefficients:
##             Estimate Std. Error z value     Pr(&gt;|z|)    
## (Intercept)  -7.8147     0.9100   -8.59      &lt; 2e-16 ***
## thick         0.6188     0.1471    4.21 0.0000259816 ***
## u.size        0.6582     0.1530    4.30 0.0000168303 ***
## nucl          0.5726     0.0992    5.77 0.0000000079 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 620.989  on 473  degrees of freedom
## Residual deviance:  97.665  on 470  degrees of freedom
## AIC: 105.7
## 
## Number of Fisher Scoring iterations: 7</code></pre>
<p>위 모델을 테스트 셋에 적용한 후, 혼돈 행렬을 이용해 측값과 실제 값을 비교해보도록 합니다.</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb109-1" data-line-number="1"><span class="kw">library</span>(caret)</a>
<a class="sourceLine" id="cb109-2" data-line-number="2"></a>
<a class="sourceLine" id="cb109-3" data-line-number="3">test.cv.probs =<span class="st"> </span><span class="kw">predict</span>(reduce.fit, <span class="dt">newdata =</span> test, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</a>
<a class="sourceLine" id="cb109-4" data-line-number="4">test.cv.probs =<span class="st"> </span><span class="kw">ifelse</span>(test.cv.probs <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>()</a>
<a class="sourceLine" id="cb109-5" data-line-number="5">test.class =<span class="st"> </span><span class="kw">ifelse</span>(test<span class="op">$</span>class <span class="op">==</span><span class="st"> &#39;malignant&#39;</span>, <span class="dv">1</span>, <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>()</a>
<a class="sourceLine" id="cb109-6" data-line-number="6"></a>
<a class="sourceLine" id="cb109-7" data-line-number="7">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(test.cv.probs, test.class)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 139   5
##          1   3  62
##                                         
##                Accuracy : 0.962         
##                  95% CI : (0.926, 0.983)
##     No Information Rate : 0.679         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.911         
##                                         
##  Mcnemar&#39;s Test P-Value : 0.724         
##                                         
##             Sensitivity : 0.979         
##             Specificity : 0.925         
##          Pos Pred Value : 0.965         
##          Neg Pred Value : 0.954         
##              Prevalence : 0.679         
##          Detection Rate : 0.665         
##    Detection Prevalence : 0.689         
##       Balanced Accuracy : 0.952         
##                                         
##        &#39;Positive&#39; Class : 0             
## </code></pre>
<p>모든 피처를 포함하는 모형에 비하면 정확도가 다소 떨어졌습니다.</p>
</div>
<div id="bic-기준-최적의-피처-선택" class="section level2">
<h2><span class="header-section-number">3.6</span> BIC 기준 최적의 피처 선택</h2>
<p><code>bestglm()</code> 함수의 IC 인자를 변경하여 타 기준 최적 피처를 선택할 수 있으며, BIC 기준 최적의 피처를 선택하도로 하겠습니다.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb111-1" data-line-number="1"><span class="kw">bestglm</span>(df, <span class="dt">IC =</span> <span class="st">&#39;BIC&#39;</span>, <span class="dt">family =</span> binomial)</a></code></pre></div>
<pre><code>## BIC
## BICq equivalent for q in (0.273173435514231, 0.577036596263764)
## Best Model:
##             Estimate Std. Error z value  Pr(&gt;|z|)
## (Intercept)  -8.6170    1.03155  -8.353 6.633e-17
## thick         0.7114    0.14752   4.822 1.419e-06
## adhsn         0.4538    0.15034   3.018 2.541e-03
## nucl          0.5580    0.09848   5.666 1.462e-08
## n.nuc         0.4291    0.11846   3.622 2.920e-04</code></pre>
<p>이번에는 thick, adhsn, nucl, n.nuc 피처가 선택되었다. 이를 토대로 추정 및 정확도를 계산해봅니다.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb113-1" data-line-number="1">bic.fit =<span class="st"> </span><span class="kw">glm</span>(class <span class="op">~</span><span class="st"> </span>thick <span class="op">+</span><span class="st"> </span>adhsn <span class="op">+</span><span class="st"> </span>nucl <span class="op">+</span><span class="st"> </span>n.nuc, <span class="dt">family =</span> binomial,</a>
<a class="sourceLine" id="cb113-2" data-line-number="2">                 <span class="dt">data =</span> train)</a>
<a class="sourceLine" id="cb113-3" data-line-number="3"></a>
<a class="sourceLine" id="cb113-4" data-line-number="4">test.bic.probs =<span class="st"> </span><span class="kw">predict</span>(bic.fit, <span class="dt">newdata =</span> test, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</a>
<a class="sourceLine" id="cb113-5" data-line-number="5">test.bic.probs =<span class="st"> </span><span class="kw">ifelse</span>(test.bic.probs <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>()</a>
<a class="sourceLine" id="cb113-6" data-line-number="6"></a>
<a class="sourceLine" id="cb113-7" data-line-number="7">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(test.bic.probs, test.class)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 138   1
##          1   4  66
##                                         
##                Accuracy : 0.976         
##                  95% CI : (0.945, 0.992)
##     No Information Rate : 0.679         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.946         
##                                         
##  Mcnemar&#39;s Test P-Value : 0.371         
##                                         
##             Sensitivity : 0.972         
##             Specificity : 0.985         
##          Pos Pred Value : 0.993         
##          Neg Pred Value : 0.943         
##              Prevalence : 0.679         
##          Detection Rate : 0.660         
##    Detection Prevalence : 0.665         
##       Balanced Accuracy : 0.978         
##                                         
##        &#39;Positive&#39; Class : 0             
## </code></pre>
<p>정확도가 0.9761으로 소폭 개선되었습니다.</p>
</div>
<div id="roc" class="section level2">
<h2><span class="header-section-number">3.7</span> ROC</h2>
<p>분류 모형을 선택할 때는 ROC(Receiver Operating Characteristic) 차트를 주로 이용합니다.</p>
<p>ROC 곡선은 거짓 긍정을 피하면서 참 긍정을 팀자하는 것 사이의 트레이드오프를 관찰하는데 사용되며, <span class="math inline">\(y\)</span>축은 참 긍정율(TPR: True Positive Rate), <span class="math inline">\(x\)</span>축은 거짓 긍정율(FPR: False Positive Rate)을 나타냅니다.</p>
<p><span class="math display">\[TPR = 긍정이라고\ 제대로\ 분류된 갯수 /\ 전체\ 긍정\ 갯수\]</span>
<span class="math display">\[FPR = 긍정이라고\ 잘못\ 분류된\ 부정\ 갯수 /\ 전체\ 부정\ 갯수\]</span>
ROC 곡선을 구성하는 점들은 거짓 긍정의 임계치가 변화할 때 참 긍정률을 나타냅니다. 곡선을 생성하기 위해 분류기의 예측을 긍정 클래스의 추정 확률로 내림차순 정렬합니다. 원점에서 시작해 참 긍정률과 거짓 긍정률에 미치는 영향은 수직 또는 수평으로 추적하는 곡선을 만듭니다.</p>
<p><img src="images/roc.png" width="50%" style="display: block; margin: auto;" /></p>
<p>다이어그램의 왼쪽 하단 모서리에서 오른쪽 상단의 모서리까지 대각선은 예측 값이 없는 분류기를 나타냅니다 이 분류기는 참 긍정과 거짓 긍정이 정확히 같은 비율로 탐지되는데, 분류기가 이 둘을 구별하지 못한다는 것을 의미하며, 다른 분류기를 판단하기 위한 기준선입니다. 이 선에 가까운 ROC 곡선은 그다지 유용하지 않은 모델을 나타냅니다.</p>
<p>분류기가 완벽하다면 True Positive는 100%, False Positive는 0%인 y축과 같을 것입니다. 실제 분류기는 위 그림처럼 ‘완벽한’ 분류기와 ‘쓸모없는’ 분류기 사이의 영역에 위치할 것입니다.</p>
<p>ROC 곡선이 완벽한 분류기에 가까울수록 분류기는 Positive 값을 더욱 잘 식별하며, 이는 AUC (Area Under Curve)로 측정할 수 있습니다. AUC는 ROC 다이어그램을 2차원 정사각형으로 취급하며, ROC 곡선의 아래 전체 영역을 측정합니다. AUC는 0.5에서 1 사이 값을 나타냅니다.</p>
<p>다음은 모형의 ROC 및 AUC를 계산하는 방법입니다.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb115-1" data-line-number="1">full.fit =<span class="st"> </span><span class="kw">glm</span>(class <span class="op">~</span>.,  <span class="dt">family =</span> binomial, <span class="dt">data =</span> train)</a>
<a class="sourceLine" id="cb115-2" data-line-number="2"></a>
<a class="sourceLine" id="cb115-3" data-line-number="3">test.full.props =<span class="st"> </span><span class="kw">predict</span>(full.fit, <span class="dt">newdata =</span> test, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</a>
<a class="sourceLine" id="cb115-4" data-line-number="4"><span class="kw">head</span>(test.full.props)</a></code></pre></div>
<pre><code>##        2        4        5        8       11       16 
## 0.960970 0.676287 0.022461 0.005702 0.001921 0.743727</code></pre>
<p>먼저 모든 피처로 로지스틱 회귀 분석을 실시한 후, <code>predict()</code> 함수를 이용해 테스트 셋에 모델을 적용합니다.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb117-1" data-line-number="1"><span class="kw">library</span>(InformationValue)</a>
<a class="sourceLine" id="cb117-2" data-line-number="2"><span class="kw">plotROC</span>(test.class, test.full.props)</a></code></pre></div>
<p><img src="03-logistic_files/figure-html/unnamed-chunk-31-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>InformationValue 패키지의 <code>plotROC()</code> 함수를 이용해 ROC 그림 및 AUC 값을 계산할 수 있습니다.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="회귀분석.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ridge-lasso.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
